{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpNBgrs9_Pkk"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import requests\n",
    "    import json\n",
    "except ImportError:\n",
    "    %pip install pandas numpy matplotlib requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import requests\n",
    "    import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AePdSssBLln"
   },
   "source": [
    "# ==========================================\n",
    "# 1. THE \"PLANT\" (Simulation Environment)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWOb01oDBLbN"
   },
   "outputs": [],
   "source": [
    "class SmartHomeEnv:\n",
    "    def __init__(self, battery_capacity=10.0, max_power=5.0, seed=42):\n",
    "        self.battery_capacity = battery_capacity # kWh\n",
    "        self.max_power = max_power # kW\n",
    "        self.soc = 0.0 # Initial State of Charge (kWh)\n",
    "        self.time_step = 0\n",
    "\n",
    "        # Set a fixed seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Internal Data Generation (The \"Real World\")\n",
    "        self.data = self._generate_scenario_data(hours=72)\n",
    "\n",
    "    def _generate_scenario_data(self, hours):\n",
    "        t = np.arange(hours)\n",
    "        # Solar: Peak at noon + random clouds\n",
    "        solar = np.maximum(0, 5 * np.sin(2 * np.pi * (t - 6) / 24))\n",
    "        solar = np.maximum(0, solar - 0.3 * np.random.weibull(0.5, size=hours))\n",
    "\n",
    "        # Load: Morning/Evening peaks\n",
    "        load = 2 + np.cos(4 * np.pi * (t - 18) / 24) + \\\n",
    "                0.8 * np.cos(2 * np.pi * (t - 14) / 24)\n",
    "        load = np.maximum(0.5, load)\n",
    "        # Price: High in evening\n",
    "        price = 0.20 + 0.20 * np.cos(2 * np.pi * (t - 18) / 24)\n",
    "\n",
    "        return pd.DataFrame({'solar': solar, 'load': load, 'price': price})\n",
    "\n",
    "    def reset(self):\n",
    "        self.soc = 0.0\n",
    "        self.time_step = 0\n",
    "        return self.data.iloc[0]\n",
    "\n",
    "    def step(self, action_kw):\n",
    "        \"\"\"\n",
    "        Executes one time step.\n",
    "        Args:\n",
    "            action_kw (float): Desired battery power (+ Charge, - Discharge)\n",
    "        Returns:\n",
    "            observation (Series): The NEXT state (load, solar, price)\n",
    "            reward (float): The cost incurred this step\n",
    "            done (bool): Is simulation over?\n",
    "            info (dict): Debug info\n",
    "        \"\"\"\n",
    "        current_data = self.data.iloc[self.time_step]\n",
    "\n",
    "        # --- 1. Apply Physics Constraints (The \"Real\" Battery) ---\n",
    "        # A. Power Limits\n",
    "        power = np.clip(action_kw, -self.max_power, self.max_power)\n",
    "\n",
    "        # B. Capacity Limits\n",
    "        if power > 0: # Charging\n",
    "            max_charge = self.battery_capacity - self.soc\n",
    "            power = min(power, max_charge)\n",
    "        else: # Discharging\n",
    "            max_discharge = self.soc\n",
    "            power = max(power, -max_discharge) # (power is negative)\n",
    "\n",
    "        # --- 2. Update State ---\n",
    "        self.soc += power # Simple energy bucket model (1 hour timestep)\n",
    "\n",
    "        # --- 3. Calculate Cost ---\n",
    "        # Grid Balance: Load + Charge = Solar + Discharge + Grid\n",
    "        # Grid = (Load - Solar) + Power\n",
    "        net_load = current_data['load'] - current_data['solar']\n",
    "        grid_kw = net_load + power\n",
    "\n",
    "        cost = grid_kw * current_data['price']\n",
    "\n",
    "        # --- 4. Prepare Next Step ---\n",
    "        self.time_step += 1\n",
    "        done = self.time_step >= len(self.data)\n",
    "\n",
    "        next_obs = None\n",
    "        if not done:\n",
    "            next_obs = self.data.iloc[self.time_step]\n",
    "\n",
    "        info = {\n",
    "            'soc': self.soc,\n",
    "            'grid_kw': grid_kw,\n",
    "            'battery_action_actual': power,\n",
    "            'load': current_data['load'],\n",
    "            'solar': current_data['solar'],\n",
    "            'price': current_data['price']\n",
    "        }\n",
    "\n",
    "        return next_obs, cost, done, info\n",
    "\n",
    "    def get_forecast(self, horizon=24):\n",
    "        \"\"\"Returns the data for the next N hours (for MPC)\"\"\"\n",
    "        start = self.time_step\n",
    "        end = min(start + horizon, len(self.data))\n",
    "        return self.data.iloc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Gymnasium Environment Wrapper ---\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    import gymnasium as gym\n",
    "    from gymnasium import spaces\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.common.env_checker import check_env\n",
    "except ImportError:\n",
    "    %pip install stable-baselines3 gymnasium shimmy\n",
    "    from pathlib import Path\n",
    "    import gymnasium as gym\n",
    "    from gymnasium import spaces\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "class HEMSGymEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Gymnasium wrapper for SmartHomeEnv to make it compatible with Stable Baselines3.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HEMSGymEnv, self).__init__()\n",
    "        self.env = SmartHomeEnv()\n",
    "        \n",
    "        # Action space: Continuous [-1, 1] representing fraction of max power\n",
    "        # We will scale this to [-max_power, max_power] inside step()\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        \n",
    "        # Observation space: [solar, load, price, soc]\n",
    "        # We use -inf to inf to avoid bounds issues, but in practice these are bounded\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        # Reset internal env\n",
    "        obs_series = self.env.reset()\n",
    "        \n",
    "        # Construct observation\n",
    "        self.current_obs = np.array([\n",
    "            obs_series['solar'],\n",
    "            obs_series['load'],\n",
    "            obs_series['price'],\n",
    "            self.env.soc\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        return self.current_obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Scale action [-1, 1] -> [-max_power, max_power]\n",
    "        action_kw = float(action[0]) * self.env.max_power\n",
    "        \n",
    "        # Step internal env\n",
    "        next_obs_series, cost, done, info = self.env.step(action_kw)\n",
    "        \n",
    "        # Reward: Negative cost (Maximize negative cost => Minimize cost)\n",
    "        reward = -cost\n",
    "        \n",
    "        # Update observation\n",
    "        if not done:\n",
    "            self.current_obs = np.array([\n",
    "                next_obs_series['solar'],\n",
    "                next_obs_series['load'],\n",
    "                next_obs_series['price'],\n",
    "                self.env.soc\n",
    "            ], dtype=np.float32)\n",
    "        else:\n",
    "            # If done, next_obs might be None or we just return the last one\n",
    "            pass\n",
    "\n",
    "        terminated = done\n",
    "        truncated = False\n",
    "        \n",
    "        return self.current_obs, reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HEMSSelfsufficientGymEnv(HEMSGymEnv):\n",
    "    def step(self, action):\n",
    "        self.current_obs, reward, terminated, truncated, info = super().step(action)\n",
    "        reward = -abs(info['grid_kw'])\n",
    "        reward = info['solar'] - max(0, info['solar'] - info['load'] - info['battery_action_actual'])\n",
    "\n",
    "        return self.current_obs, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "# --- Train the Agents ---\n",
    "envs = {\n",
    "    \"ppo_hems_cost_model.zip\": HEMSGymEnv,\n",
    "    \"ppo_hems_selfsufficient_model.zip\": HEMSSelfsufficientGymEnv,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for rl_model_path, GymEnv in envs.items():\n",
    "    rl_model_path = Path(rl_model_path)\n",
    "    if rl_model_path.exists():\n",
    "        print(f\"Trained Model exists at {rl_model_path}\")\n",
    "    else:\n",
    "        print(f\"Training RL Agent {rl_model_path}... this might take a minute.\")\n",
    "        train_env = GymEnv()\n",
    "        # Use MlpPolicy (Multi-Layer Perceptron) suitable for vector observations\n",
    "        rl_model = PPO(\"MlpPolicy\", train_env, verbose=0, learning_rate=0.0003, n_steps=2048)\n",
    "        rl_model.learn(total_timesteps=50000)\n",
    "        rl_model.save(rl_model_path)\n",
    "        print(\"Training Complete. Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4SsYQ2k_44Z"
   },
   "source": [
    "# ==========================================\n",
    "# 2. THE CONTROLLERS\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PFYN8zlorY5"
   },
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    \"\"\"Base controller: stores battery capacity and max power values and defines interface.\"\"\"\n",
    "    def __init__(self, env):\n",
    "        self.bat_cap = env.battery_capacity\n",
    "        self.max_p = env.max_power\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3LTvlBj_YJ9"
   },
   "outputs": [],
   "source": [
    "class BasicController(Controller):\n",
    "    \"\"\"Store all solar; discharge battery completely.\"\"\"\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        net_load = observation['load'] - observation['solar']\n",
    "        if net_load < 0:\n",
    "            return self.max_p\n",
    "        else:\n",
    "            return -self.max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualChargeController(Controller):\n",
    "    \"\"\"Store excess solar; discharge to meet deficits.\"\"\"\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        net_load = observation['load'] - observation['solar']\n",
    "        if net_load < 0:\n",
    "            return min(self.max_p, -net_load)\n",
    "        else:\n",
    "            return -min(self.max_p, net_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "213f3c10"
   },
   "outputs": [],
   "source": [
    "class CostOptimizedBasicController(Controller):\n",
    "    \"\"\"Charge from solar; discharge when price is high; otherwise hold.\"\"\"\n",
    "    def __init__(self, env, price_threshold=0.20):\n",
    "        super().__init__(env)\n",
    "        self.price_threshold = price_threshold\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        net_load = observation['load'] - observation['solar']\n",
    "        current_price = observation['price']\n",
    "        if net_load < 0:\n",
    "            return self.max_p\n",
    "        else:\n",
    "            if current_price > self.price_threshold:\n",
    "                return -self.max_p\n",
    "            else:\n",
    "                return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostOptimizedResidualController(Controller):\n",
    "    \"\"\"Charge from surplus solar; discharge to cover residual load when price is high; otherwise hold.\"\"\"\n",
    "    def __init__(self, env, price_threshold=0.20):\n",
    "        super().__init__(env)\n",
    "        self.price_threshold = price_threshold\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        net_load = observation['load'] - observation['solar']\n",
    "        current_price = observation['price']\n",
    "        if net_load < 0:\n",
    "            return min(self.max_p, -net_load)\n",
    "        else:\n",
    "            if current_price > self.price_threshold:\n",
    "                return -min(self.max_p, net_load)\n",
    "            else:\n",
    "                return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbsMPCController(Controller):\n",
    "    \"\"\"MPC controller using Urbs for optimization with perfect foresight.\"\"\"\n",
    "    def __init__(self, env, url=\"http://localhost:5000/simulate\"):\n",
    "        super().__init__(env)\n",
    "        self.url = url\n",
    "        self.plan = None\n",
    "        self.env = env # Need access to env for full forecast\n",
    "        self.horizon = 10000\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        # Plan once at the beginning (Perfect Foresight)\n",
    "        if self.plan is None:\n",
    "            self.plan = self._run_optimization(horizon=self.horizon)\n",
    "        \n",
    "        # Get action for current timestep\n",
    "        t = self.env.time_step\n",
    "        if t < len(self.plan):\n",
    "            return self.plan[t]\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def _run_optimization(self,horizon=10000):\n",
    "        # 1. Get Full Forecast\n",
    "        # We need the full data. env.data is available since we passed env.\n",
    "        # But to be clean, let's use get_forecast with a large horizon.\n",
    "        full_data = self.env.get_forecast(horizon=horizon) # Get everything\n",
    "        timesteps = len(full_data)\n",
    "        \n",
    "        # 2. Construct JSON Payload\n",
    "        # Normalize Solar: Urbs SupIm is usually a profile. \n",
    "        # We'll set installed capacity to max(solar) and profile to solar/max.\n",
    "        solar_profile = full_data['solar'].values\n",
    "        max_solar = solar_profile.max()\n",
    "        if max_solar == 0: max_solar = 1.0\n",
    "        norm_solar = (solar_profile / max_solar).tolist()\n",
    "        \n",
    "        load_profile = full_data['load'].tolist()\n",
    "        price_profile = full_data['price'].tolist()\n",
    "        \n",
    "        payload = {\n",
    "            \"c_timesteps\": timesteps,\n",
    "            \"global\": {\n",
    "                \"CO2 limit\": 1e15, # Infinite\n",
    "                \"Cost limit\": 1e15 # Infinite\n",
    "            },\n",
    "            \"site\": {\n",
    "                \"Main\": {\n",
    "                    \"area\": 100,\n",
    "                    \"commodity\": {\n",
    "                        \"Elec\": {\n",
    "                            \"Type\": \"Demand\",\n",
    "                            \"demand\": load_profile\n",
    "                        },\n",
    "                        \"SolarRes\": {\n",
    "                            \"Type\": \"SupIm\",\n",
    "                            \"supim\": norm_solar\n",
    "                        },\n",
    "                        \"Grid\": {\n",
    "                            \"Type\": \"Buy\",\n",
    "                            \"price\": price_profile\n",
    "                        }\n",
    "                    },\n",
    "                    \"process\": {\n",
    "                        \"PV\": {\n",
    "                            \"inst-cap\": max_solar,\n",
    "                            \"cap-lo\": 0,\n",
    "                            \"cap-up\": max_solar,\n",
    "                            \"commodity\": {\n",
    "                                \"SolarRes\": { \"Direction\": \"In\", \"ratio\": 1 },\n",
    "                                \"Elec\": { \"Direction\": \"Out\", \"ratio\": 1 }\n",
    "                            }\n",
    "                        },\n",
    "                        \"GridImport\": {\n",
    "                            \"inst-cap\": 0,\n",
    "                            \"cap-lo\": 0,\n",
    "                            \"cap-up\": 1e6,\n",
    "                            \"commodity\": {\n",
    "                                \"Grid\": { \"Direction\": \"In\", \"ratio\": 1 },\n",
    "                                \"Elec\": { \"Direction\": \"Out\", \"ratio\": 1 }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"storage\": {\n",
    "                        \"Battery\": {\n",
    "                            \"inst-cap-c\": self.bat_cap,\n",
    "                            \"cap-lo-c\": 0,\n",
    "                            \"cap-up-c\": self.bat_cap,\n",
    "                            \"inst-cap-p\": self.max_p,\n",
    "                            \"cap-lo-p\": 0,\n",
    "                            \"cap-up-p\": self.max_p,\n",
    "                            \"eff-in\": 1.0,\n",
    "                            \"eff-out\": 1.0,\n",
    "                            \"commodity\": \"Elec\",\n",
    "                            \"init\": 0.0\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 3. Send Request\n",
    "        try:\n",
    "            response = requests.post(self.url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            # 4. Parse Result\n",
    "            # result['results']['Main']['Elec']['storage']['Stored'] (Charge)\n",
    "            # result['results']['Main']['Elec']['storage']['Retrieved'] (Discharge)\n",
    "            storage_res = result['results']['Main']['Elec']['storage']\n",
    "            charge = np.array(storage_res['Stored'])\n",
    "            discharge = np.array(storage_res['Retrieved'])\n",
    "            \n",
    "            # Net action: Charge - Discharge\n",
    "            # Note: SmartHomeEnv expects positive for Charge, negative for Discharge.\n",
    "            actions = charge - discharge\n",
    "            return actions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed: {e}\")\n",
    "            # Fallback: Do nothing\n",
    "            return np.zeros(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimitedURBSController(UrbsMPCController):\n",
    "    \"\"\"MPC controller using Urbs for optimization with perfect foresight and limited horizon.\"\"\"\n",
    "    def __init__(self, env, url=\"http://localhost:5000/simulate\"):\n",
    "        super().__init__(env, url)\n",
    "        self.horizon = 24\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        # Plan once at the beginning (Perfect Foresight)\n",
    "        if self.plan is None:\n",
    "            self.plan = self._run_optimization(horizon=self.horizon)\n",
    "        \n",
    "        # Get action for current timestep\n",
    "        t = self.env.time_step\n",
    "        if t < len(self.plan):\n",
    "            return self.plan[t]\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SB3RLCostController(Controller):\n",
    "    \"\"\"\n",
    "    Controller that uses the pre-trained Stable Baselines3 model with cost optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.model = PPO.load(\"ppo_hems_cost_model.zip\")\n",
    "\n",
    "    def get_action(self, observation, current_soc):\n",
    "        # Prepare observation for the model\n",
    "        obs_vector = np.array([\n",
    "            observation['solar'],\n",
    "            observation['load'],\n",
    "            observation['price'],\n",
    "            current_soc\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Predict (deterministic=True for evaluation)\n",
    "        action, _ = self.model.predict(obs_vector, deterministic=True)\n",
    "        \n",
    "        # Scale back to kW\n",
    "        return action[0] * self.max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SB3RLSelfSufficientController(SB3RLCostController):\n",
    "    \"\"\"\n",
    "    Controller that uses the pre-trained Stable Baselines3 model with self sufficiency optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(SB3RLCostController, self).__init__(env)\n",
    "        self.model = PPO.load(\"ppo_hems_selfsufficient_model.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IDVyUZ_0L9"
   },
   "source": [
    "# ==========================================\n",
    "# 3. MAIN LOOP (The \"Gym\" Loop)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC7OWcnT_YDi"
   },
   "outputs": [],
   "source": [
    "def run_experiment(Controller):\n",
    "    # Setup\n",
    "    env = SmartHomeEnv()\n",
    "    agent = Controller(env)\n",
    "   # agent = CostOptimizedRuleBasedController(env)\n",
    "   # agent = SOCAwareRuleBasedController(env)\n",
    "    # History Storage\n",
    "    results = []\n",
    "\n",
    "    # Start\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    print(\"Starting Simulation...\")\n",
    "\n",
    "    while not done:\n",
    "        # 1. Agent decides\n",
    "        # Note: RuleBased needs current SOC to be perfect, but here we\n",
    "        # just ask for MAX and let physics clip it.\n",
    "        action_requested = agent.get_action(obs, env.soc)\n",
    "\n",
    "        # 2. Environment reacts\n",
    "        next_obs, cost, done, info = env.step(action_requested)\n",
    "\n",
    "\n",
    "\n",
    "        # 3. Store Data\n",
    "        info['action_requested'] = action_requested # Log the requested action\n",
    "        info['cost'] = cost\n",
    "        results.append(info)\n",
    "\n",
    "\n",
    "        # 4. Advance\n",
    "        obs = next_obs\n",
    "\n",
    "    # Process Results\n",
    "    df_res = pd.DataFrame(results)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkb8FWPN_rcE"
   },
   "source": [
    "# ==========================================\n",
    "# 4. VISUALIZATION\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cecfAVk6_X1y"
   },
   "outputs": [],
   "source": [
    "def plot_controller_performance(df, controller_name, total_cost):\n",
    "    print(f\"Total Cost for {controller_name}: €{total_cost:.2f}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Ax1: Physics\n",
    "    ax1.set_title(f\"{controller_name}: Power Flows\")\n",
    "    ax1.plot(df['load'], 'k--', label='Load', alpha=0.5)\n",
    "    ax1.plot(df['solar'], 'orange', label='Solar', alpha=0.5)\n",
    "    ax1.bar(df.index, df['battery_action_actual'], color='green', alpha=0.3, label='Battery Flow')\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel(\"kW\")\n",
    "\n",
    "    # Ax2: Battery State\n",
    "    ax2.set_title(f\"{controller_name}: Battery State of Charge\")\n",
    "    ax2.plot(df['soc'], 'g-', linewidth=2)\n",
    "    ax2.set_ylabel(\"kWh\")\n",
    "    ax2.set_xlabel(\"Hour\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QczxOiMplIx"
   },
   "source": [
    "# ==========================================\n",
    "# 5. COMPARISON\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "K6OFxeS6kTPQ",
    "outputId": "2ca28c4a-4bc9-43ae-ab12-1d8f46af3e07"
   },
   "outputs": [],
   "source": [
    "controllers = {\n",
    "    # \"Basic\": BasicController,\n",
    "    \"ResidualCharge\": ResidualChargeController,\n",
    "    # \"CostOptimizedBasic\": CostOptimizedBasicController,\n",
    "    \"CostOptimizedResidual\": CostOptimizedResidualController,\n",
    "    # \"LimitedURBS\": LimitedURBSController,\n",
    "    \"SB3RLCost\": SB3RLCostController,\n",
    "    \"SB3RLSelfSufficient\": SB3RLSelfSufficientController,\n",
    "    # \"UrbsMPC\": UrbsMPCController\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "for name, controller in controllers.items():\n",
    "    all_results[name] = run_experiment(controller)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "df = list(all_results.values())[0]\n",
    "ax1.plot(df['solar'], label='Solar')\n",
    "ax1.plot(df['load'], 'k--', label='Load')\n",
    "ax1.plot(df['price'], label='Price')\n",
    "for name, df in all_results.items():\n",
    "    total_cost = df['cost'].sum()\n",
    "    # print(f\"Total Cost for {name}: €{total_cost:.2f}\")\n",
    "\n",
    "\n",
    "    # Ax1: Physics\n",
    "    ax1.set_title(\"Power Flows\")\n",
    "\n",
    "\n",
    "    ax1.bar(df.index, df['battery_action_actual'], alpha=0.3, label=f'{name} \\n (Cost: {total_cost:.2f}€)')\n",
    "    ax1.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    ax1.set_ylabel(\"kW\")\n",
    "\n",
    "    # Ax2: Battery State\n",
    "    ax2.set_title(\"Battery State of Charge\")\n",
    "    ax2.plot(df['soc'], '--', linewidth=2, label=f\"{name}\")\n",
    "    ax2.set_ylabel(\"kWh\")\n",
    "    ax2.set_xlabel(\"Hour\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
